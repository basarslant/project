{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Data-Main.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93444.0</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4965.0</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93444.0</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4967.0</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93444.0</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4965.0</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93444.0</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4965.0</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93444.0</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4963.0</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital            education  default housing loan  \\\n",
       "0   45  entrepreneur  married    university.degree  unknown     yes  yes   \n",
       "1   29    technician   single    university.degree       no     yes  yes   \n",
       "2   40    management  married          high.school       no      no  yes   \n",
       "3   38    technician  married  professional.course       no     yes   no   \n",
       "4   34        admin.  married    university.degree       no      no   no   \n",
       "\n",
       "    contact month day_of_week ...   campaign  pdays  previous     poutcome  \\\n",
       "0  cellular   aug         mon ...          2    999         0  nonexistent   \n",
       "1  cellular   aug         wed ...          3    999         0  nonexistent   \n",
       "2  cellular   aug         wed ...          1    999         0  nonexistent   \n",
       "3  cellular   aug         mon ...          1    999         0  nonexistent   \n",
       "4  cellular   aug         tue ...          1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed    y  \n",
       "0          1.4         93444.0          -36.1     4965.0       5228.1   no  \n",
       "1          1.4         93444.0          -36.1     4967.0       5228.1   no  \n",
       "2          1.4         93444.0          -36.1     4965.0       5228.1   no  \n",
       "3          1.4         93444.0          -36.1     4965.0       5228.1  yes  \n",
       "4          1.4         93444.0          -36.1     4963.0       5228.1   no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi nereden aldigini yazmamissin.\n",
    "\n",
    "\n",
    "#### Data Set Information\n",
    "\n",
    "- The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \n",
    "\n",
    "- **Data size:** 86520 entries\n",
    "\n",
    "- **Data distribution:** 4120 entries for each class. It has 21 columns which contain client data and contact information, attributes and output variable.\n",
    "\n",
    "Asagidakileri veri sayfasindan alip kopyalamissin. Anlatman lazim. Sana ornekle gostereyim:\n",
    "\n",
    "#### Client Data\n",
    "\n",
    "1. **Age:** This column indicates the age of the customer. It is a numeric variable and ranges between 18 and 88.\n",
    "\n",
    "2. **Job:** This column indicates the job of the customer. There are only a few options.  These are \n",
    "   * 'admin.',\n",
    "   * 'blue-collar',\n",
    "   * 'entrepreneur',\n",
    "   * 'housemaid',\n",
    "   * 'management',\n",
    "   * 'retired',\n",
    "   * 'self-employed',\n",
    "   * 'services',\n",
    "   * 'student',\n",
    "   * 'technician',\n",
    "   * 'unemployed',\n",
    "   * 'unknown'\n",
    "   \n",
    "3. **Marital:** This column indicates the marital status of the customer. It is a categorical variable and the option are \n",
    "   * 'divorced',\n",
    "   * 'married',\n",
    "   * 'single',\n",
    "   * 'unknown'\n",
    "   \n",
    "**4.Education:** (*Categorical:*'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\t\n",
    "**5.Default:** Has credit in default? (*Categorical:* 'no','yes','unknown')\t\t\n",
    "**6.Housing:** Has housing loan? (*Categorical:*'no','yes','unknown')\t\n",
    "**7.Loan:** Has personal loan? (*Categorical:* 'no','yes','unknown')\t\n",
    "\n",
    "#### Information Of The Last Contact\n",
    "**8.Contact:** Contact communication type (*Categorical:* 'cellular','telephone')\t \n",
    "**9.Month:** Last contact month of year (*Categorical:* 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "**10.Day_of_week:** Last contact day of the week (*Categorical:* 'mon','tue','wed','thu','fri')\n",
    "**11.Duration:** Last contact duration(*Numeric;* in the range of 0 and 3643 seconds). \n",
    "\n",
    "#### Other Attributes\n",
    "**12.Campaign:** Number of contacts performed during this campaign and for this client (*Numeric;* in the range of 1 and 35)\t\n",
    "**13.Pdays:** Number of days that passed by after the client was last contacted from a previous campaign (*Numeric;* in the range of 0 and 999; 999 means client was not previously contacted)\t\n",
    "**14.Previous:** Number of contacts performed before this campaign and for this client (*Numeric;* in the range of 0 and 6)\t\t\n",
    "**15.Poutcome:** Outcome of the previous marketing campaign (*Categorical:* 'failure','nonexistent','success')\n",
    "\n",
    "#### Social And Economic Context Attributes \n",
    "**16.Emp.var.rate:** Employment variation rate (*Numeric;* in the range of -3 and 1.4; quarterly indicator)\t\t\n",
    "**17.Cons.price.idx:** Consumer price index(*Numeric;* in the range of 92201 and 94767; monthly indicator) \t\n",
    "**18.Cons.conf.idx:** Consumer confidence index (*Numeric;* in the range of -50 and -33; monthly indicator ) \t\n",
    "**19.Euribor3m:** Euribor 3 month rate (*Numeric;* in the range of 1 and 5045; daily indicator)\n",
    "**20.Nr.employed:** Number of employees (*Numeric;* in the range of 5191 and 5228.1; quarterly indicator)\t\n",
    "\n",
    "#### Output Variable \n",
    "**21.Y:** Has the client subscribed a term deposit? (*Binary:* 'yes','no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LOGISTIC REGRESSION\n",
    "\n",
    "\n",
    "#### *Introduction to Logistic Regression Model*\n",
    "\n",
    "Bu paragrafin tamamini oldugu gibi  David W. Hosmer ve Stanley Lemeshow kitabindan kaynak vermeden sanki kendin yazmis gibi yazmissin! OLMAMIS!!!!!\n",
    "\n",
    "Before beginning a study of logistic regression it is important to understand that the goal of an analysis using this method is the same as that of any model-building technique used in statistics: to find the best fitting and most parsimonious, yet biologically reasonable model to describe the relationship between an outcome variable which is dependent or response and a set of independent variables which is predictor or explanatory. These independent variables are called **covariates**.  \n",
    "   \n",
    "\n",
    "In any regression problem the key quantity is the mean value of the outcome variable, given the value of the independent variable which is called **conditional mean** and it is expressed as **\"E(Y|x)\"** where *Y* denotes the outcome variable and *x* denotes a value of the independent variable. E(Y|x) is read *\"the expected value of Y, given the value x.\"* In linear regression we assume that this mean may be expressed as an euation linear in x ( or some transformation of *x* or *Y*), such as $E(Y|x)=\\beta_{0} +\\beta_{1}x$. \n",
    "This expression implies that it is possible for E(Y|x) to take on any value as x ranges between $-\\infty$ and $+\\infty$.\n",
    "\n",
    "**Logistic Regression Model** is a statistical method for analyzing a dataset in which are *dichotomous(binary)* independent variables that determine an outcome. \n",
    "\n",
    "What distinguishes a logistic regression from the linear regression model is this. The prediction is based on the use of one or several predictors (numerical and categorical). A linear regression is not appropriate for predicting the value of a binary variable for two reasons:\n",
    "\n",
    "Su asagidakileri \"http://www.saedsayad.com/logistic_regression.htm\" adresinden yine kaynak gostermeden almisssin. OLMAZ!\n",
    "\n",
    "- A linear regression will predict values outside the acceptable range (e.g. predicting probabilities outside the range 0 to 1)\n",
    "- Since the dichotomous experiments can only have one of two possible values for each experiment, the residuals will not be normally distributed about the predicted line.\n",
    "                                                                                       \n",
    "![](http://www.saedsayad.com/images/LogReg_1.png)\n",
    "\n",
    " >On the other hand, a logistic regression produces a logistic curve, which is limited to values between 0 and 1.\n",
    " \n",
    " >In the logistic regression the constant (b0) moves the curve left and right and the slope (b1) defines the steepness of the curve. By simple transformation, the logistic regression equation can be written in terms of an odds ratio.\n",
    "\n",
    ">Finally, taking the natural log of both sides, we can write the equation in terms of log-odds (logit) which is a linear function of the predictors. The coefficient (b1) is the amount the logit (log-odds) changes with a one unit change in x. \n",
    "\n",
    "\n",
    "Yukaridakileri alintilamissin. OK. Ama kaynak gostermen lazim.\n",
    "\n",
    "\n",
    "#### Interpretation of Fitting Logistic Regression Analysis\n",
    "\n",
    "The first step is to determine what function of the dependent variable yields a linear function of the independent variables. This is called the ***link function*** [see McCullagh and Nelder(1983) or Dobson(1990)]. In this case of a linear regression model, it is the identity function since the dependent variable, by definition, is linear in the parameters. In the logistic regression model the link function is the logit transformation\n",
    "\n",
    "$$ g(x)=\\ln{\\frac{\\pi(x)}{1-\\pi(x)}}=\\beta_{0} +\\beta_{1}x $$\n",
    "\n",
    "In the regression model, the slope coefficient represents the change in the logit corresponding to a change of one unit in the independent variable (i.e. $\\beta_{1}= g(x+1)-g(x)$). Proper interpretation of the coefficient in a logistic regression model depends on being able to place meaning on the difference between two logits. Interpretation of this difference is discussed in detail on a case-by-case basis as it relates directly to the definition and meaning of a one-unit change in the independent variable. In the following sections of this chapter we consider the interpretation of the coefficients for a univariate logistic regression model for each of the possible measurement scales of the independent variable. In addition we discuss interpretation of the coefficients in multivariable models.\n",
    "\n",
    "\n",
    "#### Dichotomous Independent Variable\n",
    "  \n",
    "We begin our consideration of the interpretation of logistic regression coefficients with the situation where the independent variable is nominal scale and dichotomous(i.e. measured at two levels). This case provides the conceptual foundation for all the other situations.\n",
    "\n",
    "We assume that the independent variable, *x*, is coded as either zero or one. The difference in the logit for a subject with x=1 and x=0 is\n",
    "   \n",
    "$$\n",
    "g(1)-g(0)=[\\beta_{0} +\\beta_{1}x]- \\beta_{0}=\\beta_{1}.\n",
    "$$\n",
    "\n",
    "The algebra shown in this equation is rather straightforward. We present it in this level of detail to emphasize that the fisrt step in interpreting the effect of a covariate in a model is to express the desired logit difference in terms of the model. In this case the logit difference is equal to $\\beta_{1}$. In order to interpret this result we need to introduce and discuss a measure of association termed the *odds ratio*.\n",
    "\t \n",
    "The *odds* of the outcome being present among individuals with $x=1$ is defined as $\\frac{\\pi(1)}{1-\\pi(1)}$. Similarly the odds of the outcome being present among individuals with $x=0$ is defined as $\\frac{\\pi(0)}{1-\\pi(0)}$. The **odds ratio** is defined as the ratio of the odds for $x=1$ to the *odds* for $x=0$ and is given by the equation\n",
    "   \n",
    "$$\n",
    "\\text{Odds Ratio} = \\frac{\\frac{\\pi(1)}{1-\\pi(1)}}{\\frac{\\pi(0)}{1-\\pi(0)}}\n",
    "$$\n",
    "\n",
    "\n",
    "*************** sayfa 49-50 resim\n",
    "\n",
    "  \n",
    "Hence for logistic regression with a dichotomous independent variable coded 1 and 0, the relationship between the odds ratio and the regression coefficient is Odds Ratio$= \\mathrm{e}^{\\beta_{1}}$.\n",
    "\n",
    "This simple relationship between the coefficient and the odds ratio is the fundamental reason why logistic regression has proven to be such a powerful analytic research tool.\n",
    "\n",
    " The interpretation given for the odds ratio is based on the fact that in many instances it approximates a quantity called **the relative risk**. This parameter is equal to the ratio $\\frac{\\pi(1)}{\\pi(0)}$. It follows that the odds ratio approximates the relative risk $\\frac{1-\\pi(0)}{1-\\pi(1)}\\approx 1$.\n",
    "This holds when $\\pi(x)$ is small for both $x=1$ and $x=0$.\n",
    "\n",
    "\n",
    "#### *Polytomous (Multinomial) Logistic Regression Analysis* \n",
    "\n",
    "Where the response is a binary variable with 'success' and 'failure' being only two categories. But logistic regression can be extended to handle responses, Y, that are polytomous, i.e. taking $r > 2$ categories. \n",
    "   \n",
    "When $r = 2$, Y is dichotomous and we can model log of odds that an event occurs or does not occur. For binary logistic regression there is only 1 logit that we can form.\n",
    "   \n",
    "$$ logit(\\pi)=\\log{\\frac{\\pi(x)}{1-\\pi(x)}} $$\n",
    "   \n",
    "When r > 2, we have a multi-category or polytomous response variable. There are $r (r âˆ’ 1)/2$ *logits (odds)* that we can form, but only $(r âˆ’ 1)$ are non-redundant. There are different ways to form a set of $(r âˆ’ 1)$ non-redundant logits, and these will lead to different polytomous (multinomial) logistic regression models.\n",
    "   \n",
    "Multinomial Logistic Regression models how multinomial response variable Y depends on a set of k explanatory variables $x=(x_{1},x_{2},...,x_{p})$. This is also a Generalized Linear Model where the random component assumes that the distribution of Y is  Multinomial(n,Ï€), where Ï€ is a vector with probabilities of *\"success\"* for each category. The systematic component are explanatory variables (can be continuous, discrete, or both) and are linear in the parameters, e.g., $\\beta_{0} +\\beta_{1}x_{1}+\\beta_{2}x_{2}+...+\\beta_{p}x_{p}$. Again, transformation of the X's themselves are allowed like in linear regression. The *link function* is the generalized **Logit**, that it the logit link for each pair of non-redundant logits as discussed above. \n",
    "  \n",
    "For the moment we will assume that each of these variables is at least interval scale. Let the conditional probability that the outcome is present be denoted by $P(Y=1|x)= \\pi(x)$. The ***logit*** of the multiple logistic regression model is given by the equation \n",
    "\n",
    "$$ g(x)=\\beta_{0} +\\beta_{1}x_{1}+\\beta_{2}x_{2}+...+\\beta_{p}x_{p} $$\n",
    "\n",
    "in which case the logistic regression model is\n",
    "\n",
    "$$ \\pi(x)=\\frac{\\mathrm{e}^{g(x)}}{1+\\mathrm{e}^{g(x)}} $$\n",
    "\n",
    "The multiple logistic regression model can be written as follows:\n",
    "\n",
    "$$\n",
    "\\hat{p} = \\frac{\\beta_{0} +\\beta_{1}x_{1}+\\beta_{2}x_{2}+...+\\beta_{p}x_{p}}{1-\\beta_{0} +\\beta_{1}x_{1}+\\beta_{2}x_{2}+...+\\beta_{p}x_{p}}\n",
    "$$\n",
    "\n",
    "\\hat{p} is the expected probability that the outcome is present; x_{1} through x_{p} are distinct independent variables; and \\beta_{0} through \\beta_{p} are the regression coefficients. The multiple logistic regression model is sometimes written differently. In the following form, the outcome is the expected log of the odds that the outcome is present,\n",
    "\n",
    "$$ \\ln{\\frac{\\hat{p}}{1-\\hat{p}}}=\\beta_{0} +\\beta_{1}x_{1}+\\beta_{2}x_{2}+...+\\beta_{p}x_{p} $$\n",
    "\n",
    "\n",
    "When analyzing a polytomous response, it's important to note whether the response is **ordinal** (consisting of ordered categories) or **nominal** (consisting of unordered categories). For binary logistic model this question does not arise.\n",
    "\n",
    "Some types of models are appropriate only for ordinal responses; e.g., *cumulative logits model, adjacent categories model, continuation ratios model* and other models may be used whether the response is ordinal or nominal; e.g., baseline *logit model, and conditional logit model.*\n",
    "\n",
    "If the response is *ordinal*, we do not necessarily have to take the ordering into account, but only very rarely this information is ignored. Ordinality in the response is a vital information; neglecting it almost always will lead to sub-optimal models. Using the natural ordering can\n",
    "\n",
    "- lead to a simpler, more parsimonious model and\n",
    "- increase power to detect relationships with other variables.\n",
    "\n",
    " If the response variable is polytomous and all the potential predictors are discrete as well, we could describe the multi-way contingency table by a *loglinear model*. However, if you are analyzing a set of categorical variables, and one of them is clearly a \"response\" while the others are predictors, I recommend that you use logistic rather than loglinear models. \n",
    "\n",
    "***Fitting a loglinear model in this setting could have two disadvantages:***\n",
    "\n",
    "- It has many more parameters, and many of them are not of interest. The loglinear model, as we will learn later, describes the joint distribution of all the variables, whereas the logistic model describes only the conditional distribution of the response given the predictors.\n",
    "- The loglinear model is often more complicated to interpret. In the loglinear model, the effect of a predictor X on the response Y is described by the XY association. In a logit model, however, the effect of X on Y is a main effect.\n",
    "\n",
    "\n",
    "#### ***RESOURCES:***\n",
    "\n",
    "- http://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "- http://resource.heartonline.cn/20150528/1_3kOQSTg.pdf\n",
    "- https://onlinecourses.science.psu.edu/stat504/node/172\n",
    "- http://www.saedsayad.com/logistic_regression.htm\n",
    "- https://www.medcalc.org/manual/logistic_regression.php\n",
    "- http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_multivariable/BS704_Multivariable8.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUPPORT VECTOR MACHINE\n",
    "\n",
    "\n",
    "#### Introduction to Classification\n",
    "\n",
    "\n",
    "   The classification problem can be restricted to consideration of the two-class problem without loss of generality. The goal is to separate the two classes by a function which is induced from available examples and it is to produce a classifier that will work well on unseen examples, i.e. it generalises well. \n",
    "   \n",
    "   \n",
    "*********Page 5 Figure 2.1 and Figure 2.3 : http://users.ecs.soton.ac.uk/srg/publications/pdf/SVM.pdf\n",
    "http://www.jaist.jp/~h-yamada/pdf/iwpt2003.pdf\n",
    "\n",
    "\n",
    "Asagidaki metin oldugu gibi \"http://www.statsoft.com/textbook/support-vector-machines\" adresinden alinmis. OLMAZ!!!!\n",
    "\n",
    "   Support Vector Machines are based on the concept of decision planes that define decision boundaries. A decision plane is one that separates between a set of objects having different class memberships. A schematic example is shown in the illustration below. In this example, the objects belong either to class **green** or **red**. The separating line defines a boundary on the right side of which all objects are green and to the left of which all objects are red. Any new object (white circle) falling to the right is labeled, i.e., classified, as green (or classified as RED should it fall to the left of the separating line).\n",
    "\n",
    "![](http://www.statsoft.com/textbook/graphics/SVMIntro1.gif)\n",
    "\n",
    "   The above is a classic example of a linear classifier, i.e., a classifier that separates a set of objects into their respective groups (green and red in this case) with a line. Most classification tasks, however, are not that simple, and often more complex structures are needed in order to make an optimal separation, i.e., correctly classify new objects (test cases) on the basis of the examples that are available (train cases). This situation is depicted in the illustration below. Compared to the previous schematic, it is clear that a full separation of the green and red objects would require a curve (which is more complex than a line). Classification tasks based on drawing separating lines to distinguish between objects of different class memberships are known as hyperplane classifiers. Support Vector Machines are particularly suited to handle such tasks.\n",
    "\n",
    "![](http://www.statsoft.com/textbook/graphics/SVMIntro2.gif)\n",
    "\n",
    "   The illustration below shows the basic idea behind Support Vector Machines. Here we see the original objects (left side of the schematic) mapped, i.e., rearranged, using a set of mathematical functions, known as kernels. The process of rearranging the objects is known as mapping (transformation). Note that in this new setting, the mapped objects (right side of the schematic) is linearly separable and, thus, instead of constructing the complex curve (left schematic), all we have to do is to find an optimal line that can separate the green and the red objects.\n",
    "\n",
    "![](http://www.statsoft.com/textbook/graphics/SVMIntro3.gif)\n",
    "\n",
    "There are many possible linear classifiers that can separate the data, but there is only one that maximises the **margin** (*maximises the distance between it and the nearest data point of each class*). This linear classifier is termed the optimal separating **hyperplane** which is ***support vector***.  Intuitively, we would expect this boundary to generalise well as opposed to the other possible boundaries.\n",
    "\n",
    "![](http://www.saedsayad.com/images/SVM_2.png)\n",
    "\n",
    "#### Algorithm:\n",
    "\n",
    "- Define an optimal hyperplane: maximize margin\n",
    "- Extend the above definition for non-linearly separable problems: have a penalty term for misclassifications.\n",
    "- Map data to high dimensional space where it is easier to classify with linear decision surfaces: reformulate problem so that data is mapped implicitly to this space.\n",
    "- To define an optimal hyperplane we need to maximize the width of the margin (w).\n",
    "\n",
    "\n",
    "![](http://www.saedsayad.com/images/SVM_optimize.png)\n",
    "![](http://www.saedsayad.com/images/SVM_optimize_1.png)\n",
    "\n",
    ">We find w and b by solving the following objective function using Quadratic Programming.\n",
    "\n",
    "![](http://www.saedsayad.com/images/SVM_optimize_2.png)\n",
    "\n",
    "The beauty of SVM is that if the data is *linearly separable*, there is a unique global minimum value. An ideal SVM analysis should produce a hyperplane that completely separates the vectors (cases) into two non-overlapping classes. However, perfect separation may not be possible, or it may result in a model with so many cases that the model does not classify correctly. In this situation SVM finds the hyperplane that ***maximizes the margin and minimizes the misclassifications***.\n",
    "\n",
    "#### Kernel Function \n",
    "\n",
    "Bunu da \"http://www.saedsayad.com/support_vector_machine.htm\" adresinden almissin oldugu gibi. Bu da olmamis.\n",
    "\n",
    "The simplest way to separate two groups of data is with a straight line (1 dimension), flat plane (2 dimensions) or an N-dimensional hyperplane. However, there are situations where a nonlinear region can separate the groups more efficiently. SVM handles this by using a kernel function (nonlinear) to map the data into a different space where a hyperplane (linear) cannot be used to do the separation. It means a non-linear function is learned by a linear learning machine in a high-dimensional feature space while the capacity of the system is controlled by a parameter that does not depend on the dimensionality of the space. This is called **kernel trick** which means *the kernel function transform the data into a higher dimensional feature space to make it possible to perform the linear separation*.  \n",
    "\n",
    "\n",
    "\n",
    "![](http://www.saedsayad.com/images/SVM_4.png)\n",
    "![](http://www.statsoft.com/textbook/graphics/SVMIntro15.gif)\n",
    "\n",
    "where $K(X_{i},X_{j})= \\phi(X_{i}). \\phi(X_{j})$ that is, the kernel function, represents a dot product of input data points mapped into the higher dimensional feature space by transformation.\n",
    "\n",
    "* Gamma(\\gamma) is an adjustable parameter of certain kernel functions.\n",
    "* *The Radial Basis Function Kernel*, also called the RBF kernel, or Gaussian kernel, is a kernel that is in the form of a radial basis function (more specifically, a Gaussian function).\n",
    "\n",
    "\n",
    "Map data into new space, then take the inner product of the new vectors. The image of the inner product of the data is the inner product of the images of the data. Two kernel functions are shown below.\n",
    "   \n",
    "![](http://www.saedsayad.com/images/SVM_kernel_1.png)\n",
    "   \n",
    "\n",
    "##### REFERENCES:\n",
    "\n",
    "- http://users.ecs.soton.ac.uk/srg/publications/pdf/SVM.pdf\n",
    "- http://www.jaist.jp/~h-yamada/pdf/iwpt2003.pdf\n",
    "- http://www.statsoft.com/Textbook/Support-Vector-Machines#overview\n",
    "- http://www.saedsayad.com/support_vector_machine.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
